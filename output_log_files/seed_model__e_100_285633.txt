==========================================
SLURM_JOB_ID = 285633
SLURM_NODELIST = gnode55
SLURM_JOB_GPUS = 3
==========================================
GPU available: True, used: True
TPU available: False, using: 0 TPU cores
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
Set SLURM handle signals.

  | Name    | Type   | Params
-----------------------------------
0 | alexnet | ResNet | 11 M  
Validation sanity check: 0it [00:00, ?it/s]Validation sanity check:  50%|█████     | 1/2 [00:02<00:02,  2.45s/it]                                                                      Training: 0it [00:00, ?it/s]Training:   0%|          | 0/70 [00:00<?, ?it/s]Epoch 0:   0%|          | 0/70 [00:00<?, ?it/s] /home/sandeep.nagar/anaconda3/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:45: UserWarning: The {log:dict keyword} was deprecated in 0.9.1 and will be removed in 1.0.0
Please use self.log(...) inside the lightningModule instead.

# log on a step or aggregate epoch metric to the logger and/or progress bar
# (inside LightningModule)
self.log('train_loss', loss, on_step=True, on_epoch=True, prog_bar=True)
  warnings.warn(*args, **kwargs)
Epoch 0:   1%|▏         | 1/70 [00:02<03:14,  2.82s/it]Epoch 0:   1%|▏         | 1/70 [00:02<03:14,  2.82s/it, loss=7.055, v_num=285633, train_acc=0]Epoch 0:   3%|▎         | 2/70 [00:02<01:41,  1.50s/it, loss=7.055, v_num=285633, train_acc=0]Epoch 0:   3%|▎         | 2/70 [00:02<01:41,  1.50s/it, loss=6.303, v_num=285633, train_acc=0.273]Epoch 0:   4%|▍         | 3/70 [00:03<01:10,  1.06s/it, loss=6.303, v_num=285633, train_acc=0.273]Epoch 0:   4%|▍         | 3/70 [00:03<01:10,  1.06s/it, loss=5.496, v_num=285633, train_acc=0.461]Epoch 0:   6%|▌         | 4/70 [00:04<01:19,  1.20s/it, loss=5.496, v_num=285633, train_acc=0.461]Epoch 0:   6%|▌         | 4/70 [00:04<01:19,  1.20s/it, loss=4.832, v_num=285633, train_acc=0.41] Epoch 0:   7%|▋         | 5/70 [00:05<01:05,  1.00s/it, loss=4.832, v_num=285633, train_acc=0.41]Epoch 0:   7%|▋         | 5/70 [00:05<01:05,  1.00s/it, loss=4.365, v_num=285633, train_acc=0.426]Epoch 0:   9%|▊         | 6/70 [00:05<00:55,  1.16it/s, loss=4.365, v_num=285633, train_acc=0.426]Epoch 0:   9%|▊         | 6/70 [00:05<00:55,  1.16it/s, loss=3.929, v_num=285633, train_acc=0.438]Epoch 0:  10%|█         | 7/70 [00:05<00:48,  1.30it/s, loss=3.929, v_num=285633, train_acc=0.438]Epoch 0:  10%|█         | 7/70 [00:05<00:48,  1.30it/s, loss=3.562, v_num=285633, train_acc=0.371]Epoch 0:  11%|█▏        | 8/70 [00:07<00:54,  1.14it/s, loss=3.562, v_num=285633, train_acc=0.371]Epoch 0:  11%|█▏        | 8/70 [00:07<00:54,  1.14it/s, loss=3.278, v_num=285633, train_acc=0.434]Epoch 0:  13%|█▎        | 9/70 [00:07<00:49,  1.24it/s, loss=3.278, v_num=285633, train_acc=0.434]Epoch 0:  13%|█▎        | 9/70 [00:07<00:49,  1.24it/s, loss=3.050, v_num=285633, train_acc=0.449]Epoch 0:  14%|█▍        | 10/70 [00:07<00:44,  1.35it/s, loss=3.050, v_num=285633, train_acc=0.449]Epoch 0:  14%|█▍        | 10/70 [00:07<00:44,  1.35it/s, loss=2.862, v_num=285633, train_acc=0.488]Epoch 0:  16%|█▌        | 11/70 [00:07<00:40,  1.45it/s, loss=2.862, v_num=285633, train_acc=0.488]Epoch 0:  16%|█▌        | 11/70 [00:07<00:40,  1.45it/s, loss=2.711, v_num=285633, train_acc=0.453]Epoch 0:  17%|█▋        | 12/70 [00:09<00:45,  1.29it/s, loss=2.711, v_num=285633, train_acc=0.453]Epoch 0:  17%|█▋        | 12/70 [00:09<00:45,  1.29it/s, loss=2.587, v_num=285633, train_acc=0.438]Epoch 0:  19%|█▊        | 13/70 [00:09<00:41,  1.37it/s, loss=2.587, v_num=285633, train_acc=0.438]Epoch 0:  19%|█▊        | 13/70 [00:09<00:41,  1.37it/s, loss=2.478, v_num=285633, train_acc=0.492]Epoch 0:  20%|██        | 14/70 [00:09<00:38,  1.45it/s, loss=2.478, v_num=285633, train_acc=0.492]Epoch 0:  20%|██        | 14/70 [00:09<00:38,  1.45it/s, loss=2.379, v_num=285633, train_acc=0.484]Epoch 0:  21%|██▏       | 15/70 [00:09<00:36,  1.52it/s, loss=2.379, v_num=285633, train_acc=0.484]Epoch 0:  21%|██▏       | 15/70 [00:09<00:36,  1.52it/s, loss=2.294, v_num=285633, train_acc=0.504]Epoch 0:  23%|██▎       | 16/70 [00:11<00:38,  1.39it/s, loss=2.294, v_num=285633, train_acc=0.504]Epoch 0:  23%|██▎       | 16/70 [00:11<00:38,  1.39it/s, loss=2.218, v_num=285633, train_acc=0.484]Epoch 0:  24%|██▍       | 17/70 [00:11<00:36,  1.45it/s, loss=2.218, v_num=285633, train_acc=0.484]Epoch 0:  24%|██▍       | 17/70 [00:11<00:36,  1.45it/s, loss=2.150, v_num=285633, train_acc=0.5]  Epoch 0:  26%|██▌       | 18/70 [00:11<00:34,  1.52it/s, loss=2.150, v_num=285633, train_acc=0.5]Epoch 0:  26%|██▌       | 18/70 [00:11<00:34,  1.52it/s, loss=2.090, v_num=285633, train_acc=0.527]Epoch 0:  27%|██▋       | 19/70 [00:12<00:32,  1.58it/s, loss=2.090, v_num=285633, train_acc=0.527]Epoch 0:  27%|██▋       | 19/70 [00:12<00:32,  1.58it/s, loss=2.034, v_num=285633, train_acc=0.578]Epoch 0:  29%|██▊       | 20/70 [00:13<00:33,  1.50it/s, loss=2.034, v_num=285633, train_acc=0.578]Epoch 0:  29%|██▊       | 20/70 [00:13<00:33,  1.50it/s, loss=1.993, v_num=285633, train_acc=0.484]Epoch 0:  30%|███       | 21/70 [00:13<00:31,  1.55it/s, loss=1.993, v_num=285633, train_acc=0.484]Epoch 0:  30%|███       | 21/70 [00:13<00:31,  1.55it/s, loss=1.692, v_num=285633, train_acc=0.512]Epoch 0:  31%|███▏      | 22/70 [00:13<00:29,  1.61it/s, loss=1.692, v_num=285633, train_acc=0.512]Epoch 0:  31%|███▏      | 22/70 [00:13<00:29,  1.61it/s, loss=1.467, v_num=285633, train_acc=0.555]Epoch 0:  33%|███▎      | 23/70 [00:13<00:28,  1.66it/s, loss=1.467, v_num=285633, train_acc=0.555]Epoch 0:  33%|███▎      | 23/70 [00:13<00:28,  1.66it/s, loss=1.327, v_num=285633, train_acc=0.539]Epoch 0:  34%|███▍      | 24/70 [00:14<00:28,  1.63it/s, loss=1.327, v_num=285633, train_acc=0.539]Epoch 0:  34%|███▍      | 24/70 [00:14<00:28,  1.63it/s, loss=1.243, v_num=285633, train_acc=0.496]Epoch 0:  36%|███▌      | 25/70 [00:14<00:26,  1.67it/s, loss=1.243, v_num=285633, train_acc=0.496]Epoch 0:  36%|███▌      | 25/70 [00:14<00:26,  1.67it/s, loss=1.173, v_num=285633, train_acc=0.527]Epoch 0:  37%|███▋      | 26/70 [00:15<00:25,  1.72it/s, loss=1.173, v_num=285633, train_acc=0.527]Epoch 0:  37%|███▋      | 26/70 [00:15<00:25,  1.72it/s, loss=1.139, v_num=285633, train_acc=0.527]Epoch 0:  39%|███▊      | 27/70 [00:15<00:24,  1.76it/s, loss=1.139, v_num=285633, train_acc=0.527]Epoch 0:  39%|███▊      | 27/70 [00:15<00:24,  1.76it/s, loss=1.124, v_num=285633, train_acc=0.488]Epoch 0:  40%|████      | 28/70 [00:16<00:24,  1.74it/s, loss=1.124, v_num=285633, train_acc=0.488]Epoch 0:  40%|████      | 28/70 [00:16<00:24,  1.74it/s, loss=1.111, v_num=285633, train_acc=0.562]Epoch 0:  41%|████▏     | 29/70 [00:16<00:23,  1.78it/s, loss=1.111, v_num=285633, train_acc=0.562]Epoch 0:  41%|████▏     | 29/70 [00:16<00:23,  1.78it/s, loss=1.097, v_num=285633, train_acc=0.566]Epoch 0:  43%|████▎     | 30/70 [00:16<00:21,  1.82it/s, loss=1.097, v_num=285633, train_acc=0.566]Epoch 0:  43%|████▎     | 30/70 [00:16<00:21,  1.82it/s, loss=1.094, v_num=285633, train_acc=0.496]Epoch 0:  44%|████▍     | 31/70 [00:16<00:20,  1.86it/s, loss=1.094, v_num=285633, train_acc=0.496]Epoch 0:  44%|████▍     | 31/70 [00:16<00:20,  1.86it/s, loss=1.087, v_num=285633, train_acc=0.523]Epoch 0:  46%|████▌     | 32/70 [00:17<00:20,  1.83it/s, loss=1.087, v_num=285633, train_acc=0.523]Epoch 0:  46%|████▌     | 32/70 [00:17<00:20,  1.83it/s, loss=1.076, v_num=285633, train_acc=0.555]Epoch 0:  47%|████▋     | 33/70 [00:17<00:19,  1.87it/s, loss=1.076, v_num=285633, train_acc=0.555]Epoch 0:  47%|████▋     | 33/70 [00:17<00:19,  1.87it/s, loss=1.069, v_num=285633, train_acc=0.543]Epoch 0:  49%|████▊     | 34/70 [00:17<00:19,  1.89it/s, loss=1.069, v_num=285633, train_acc=0.543]Epoch 0:  49%|████▊     | 34/70 [00:17<00:19,  1.89it/s, loss=1.064, v_num=285633, train_acc=0.543]Epoch 0:  50%|█████     | 35/70 [00:18<00:18,  1.93it/s, loss=1.064, v_num=285633, train_acc=0.543]Epoch 0:  50%|█████     | 35/70 [00:18<00:18,  1.93it/s, loss=1.063, v_num=285633, train_acc=0.52] Epoch 0:  51%|█████▏    | 36/70 [00:18<00:17,  1.90it/s, loss=1.063, v_num=285633, train_acc=0.52]Epoch 0:  51%|█████▏    | 36/70 [00:18<00:17,  1.90it/s, loss=1.057, v_num=285633, train_acc=0.578]Epoch 0:  53%|█████▎    | 37/70 [00:19<00:17,  1.94it/s, loss=1.057, v_num=285633, train_acc=0.578]Epoch 0:  53%|█████▎    | 37/70 [00:19<00:17,  1.94it/s, loss=1.057, v_num=285633, train_acc=0.516]Epoch 0:  54%|█████▍    | 38/70 [00:19<00:16,  1.95it/s, loss=1.057, v_num=285633, train_acc=0.516]Epoch 0:  54%|█████▍    | 38/70 [00:19<00:16,  1.95it/s, loss=1.054, v_num=285633, train_acc=0.551]Epoch 0:  56%|█████▌    | 39/70 [00:19<00:15,  1.98it/s, loss=1.054, v_num=285633, train_acc=0.551]Epoch 0:  56%|█████▌    | 39/70 [00:19<00:15,  1.98it/s, loss=1.057, v_num=285633, train_acc=0.52] Epoch 0:  57%|█████▋    | 40/70 [00:20<00:15,  1.97it/s, loss=1.057, v_num=285633, train_acc=0.52]Epoch 0:  57%|█████▋    | 40/70 [00:20<00:15,  1.97it/s, loss=1.050, v_num=285633, train_acc=0.535]Epoch 0:  59%|█████▊    | 41/70 [00:20<00:14,  2.00it/s, loss=1.050, v_num=285633, train_acc=0.535]Epoch 0:  59%|█████▊    | 41/70 [00:20<00:14,  2.00it/s, loss=1.052, v_num=285633, train_acc=0.512]Epoch 0:  60%|██████    | 42/70 [00:20<00:13,  2.00it/s, loss=1.052, v_num=285633, train_acc=0.512]Epoch 0:  60%|██████    | 42/70 [00:20<00:13,  2.00it/s, loss=1.053, v_num=285633, train_acc=0.547]Epoch 0:  61%|██████▏   | 43/70 [00:21<00:13,  2.03it/s, loss=1.053, v_num=285633, train_acc=0.547]Epoch 0:  61%|██████▏   | 43/70 [00:21<00:13,  2.03it/s, loss=1.051, v_num=285633, train_acc=0.516]Epoch 0:  63%|██████▎   | 44/70 [00:21<00:12,  2.02it/s, loss=1.051, v_num=285633, train_acc=0.516]Epoch 0:  63%|██████▎   | 44/70 [00:21<00:12,  2.02it/s, loss=1.044, v_num=285633, train_acc=0.527]Epoch 0:  64%|██████▍   | 45/70 [00:21<00:12,  2.05it/s, loss=1.044, v_num=285633, train_acc=0.527]Epoch 0:  64%|██████▍   | 45/70 [00:21<00:12,  2.05it/s, loss=1.041, v_num=285633, train_acc=0.555]Epoch 0:  66%|██████▌   | 46/70 [00:22<00:11,  2.04it/s, loss=1.041, v_num=285633, train_acc=0.555]Epoch 0:  66%|██████▌   | 46/70 [00:22<00:11,  2.04it/s, loss=1.037, v_num=285633, train_acc=0.547]Epoch 0:  67%|██████▋   | 47/70 [00:22<00:11,  2.07it/s, loss=1.037, v_num=285633, train_acc=0.547]Epoch 0:  67%|██████▋   | 47/70 [00:22<00:11,  2.07it/s, loss=1.035, v_num=285633, train_acc=0.543]Epoch 0:  69%|██████▊   | 48/70 [00:23<00:10,  2.07it/s, loss=1.035, v_num=285633, train_acc=0.543]Epoch 0:  69%|██████▊   | 48/70 [00:23<00:10,  2.07it/s, loss=1.031, v_num=285633, train_acc=0.605]Epoch 0:  70%|███████   | 49/70 [00:23<00:10,  2.10it/s, loss=1.031, v_num=285633, train_acc=0.605]Epoch 0:  70%|███████   | 49/70 [00:23<00:10,  2.10it/s, loss=1.030, v_num=285633, train_acc=0.594]Epoch 0:  71%|███████▏  | 50/70 [00:24<00:09,  2.08it/s, loss=1.030, v_num=285633, train_acc=0.594]Epoch 0:  71%|███████▏  | 50/70 [00:24<00:09,  2.08it/s, loss=1.027, v_num=285633, train_acc=0.531]Epoch 0:  73%|███████▎  | 51/70 [00:24<00:09,  2.11it/s, loss=1.027, v_num=285633, train_acc=0.531]Epoch 0:  73%|███████▎  | 51/70 [00:24<00:09,  2.11it/s, loss=1.021, v_num=285633, train_acc=0.586]Epoch 0:  74%|███████▍  | 52/70 [00:24<00:08,  2.12it/s, loss=1.021, v_num=285633, train_acc=0.586]Epoch 0:  74%|███████▍  | 52/70 [00:24<00:08,  2.12it/s, loss=1.022, v_num=285633, train_acc=0.535]Epoch 0:  76%|███████▌  | 53/70 [00:24<00:07,  2.15it/s, loss=1.022, v_num=285633, train_acc=0.535]Epoch 0:  76%|███████▌  | 53/70 [00:24<00:07,  2.15it/s, loss=1.022, v_num=285633, train_acc=0.57] Epoch 0:  77%|███████▋  | 54/70 [00:25<00:07,  2.13it/s, loss=1.022, v_num=285633, train_acc=0.57]Epoch 0:  77%|███████▋  | 54/70 [00:25<00:07,  2.13it/s, loss=1.022, v_num=285633, train_acc=0.59]Epoch 0:  79%|███████▊  | 55/70 [00:25<00:06,  2.15it/s, loss=1.022, v_num=285633, train_acc=0.59]Epoch 0:  79%|███████▊  | 55/70 [00:25<00:06,  2.15it/s, loss=1.017, v_num=285633, train_acc=0.574]Epoch 0:  80%|████████  | 56/70 [00:25<00:06,  2.18it/s, loss=1.017, v_num=285633, train_acc=0.574]Epoch 0:  80%|████████  | 56/70 [00:25<00:06,  2.18it/s, loss=1.017, v_num=285633, train_acc=0.597]
Validating: 0it [00:00, ?it/s][A/home/sandeep.nagar/anaconda3/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:45: UserWarning: The {progress_bar:dict keyword} was deprecated in 0.9.1 and will be removed in 1.0.0
Please use self.log(...) inside the lightningModule instead.

# log on a step or aggregate epoch metric to the logger and/or progress bar
# (inside LightningModule)
self.log('train_loss', loss, on_step=True, on_epoch=True, prog_bar=True)
  warnings.warn(*args, **kwargs)

Validating:   7%|▋         | 1/14 [00:01<00:15,  1.20s/it][AEpoch 0:  81%|████████▏ | 57/70 [00:26<00:06,  2.12it/s, loss=1.017, v_num=285633, train_acc=0.597]
Validating:  14%|█▍        | 2/14 [00:01<00:10,  1.12it/s][AEpoch 0:  83%|████████▎ | 58/70 [00:27<00:05,  2.14it/s, loss=1.017, v_num=285633, train_acc=0.597]
Validating:  29%|██▊       | 4/14 [00:01<00:06,  1.56it/s][AEpoch 0:  86%|████████▌ | 60/70 [00:27<00:04,  2.20it/s, loss=1.017, v_num=285633, train_acc=0.597]
Validating:  36%|███▌      | 5/14 [00:02<00:06,  1.39it/s][A
Validating:  43%|████▎     | 6/14 [00:02<00:04,  1.72it/s][AEpoch 0:  89%|████████▊ | 62/70 [00:28<00:03,  2.18it/s, loss=1.017, v_num=285633, train_acc=0.597]
Validating:  50%|█████     | 7/14 [00:02<00:03,  2.26it/s][AEpoch 0:  91%|█████████▏| 64/70 [00:28<00:02,  2.24it/s, loss=1.017, v_num=285633, train_acc=0.597]
Validating:  64%|██████▍   | 9/14 [00:03<00:02,  2.05it/s][A
Validating:  71%|███████▏  | 10/14 [00:04<00:01,  2.43it/s][AEpoch 0:  94%|█████████▍| 66/70 [00:29<00:01,  2.21it/s, loss=1.017, v_num=285633, train_acc=0.597]
Validating:  79%|███████▊  | 11/14 [00:04<00:01,  2.70it/s][AEpoch 0:  97%|█████████▋| 68/70 [00:30<00:00,  2.25it/s, loss=1.017, v_num=285633, train_acc=0.597]
Validating:  93%|█████████▎| 13/14 [00:05<00:00,  2.41it/s][AEpoch 0: 100%|██████████| 70/70 [00:31<00:00,  2.24it/s, loss=1.017, v_num=285633, train_acc=0.597]Traceback (most recent call last):
  File "main.py", line 148, in <module>
    trainer.fit(model)
  File "/home/sandeep.nagar/anaconda3/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py", line 439, in fit
    results = self.accelerator_backend.train()
  File "/home/sandeep.nagar/anaconda3/lib/python3.8/site-packages/pytorch_lightning/accelerators/gpu_accelerator.py", line 54, in train
    results = self.train_or_test()
  File "/home/sandeep.nagar/anaconda3/lib/python3.8/site-packages/pytorch_lightning/accelerators/accelerator.py", line 66, in train_or_test
    results = self.trainer.train()
  File "/home/sandeep.nagar/anaconda3/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py", line 482, in train
    self.train_loop.run_training_epoch()
  File "/home/sandeep.nagar/anaconda3/lib/python3.8/site-packages/pytorch_lightning/trainer/training_loop.py", line 569, in run_training_epoch
    self.trainer.run_evaluation(test_mode=False)
  File "/home/sandeep.nagar/anaconda3/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py", line 609, in run_evaluation
    self.evaluation_loop.on_evaluation_end()
  File "/home/sandeep.nagar/anaconda3/lib/python3.8/site-packages/pytorch_lightning/trainer/evaluation_loop.py", line 109, in on_evaluation_end
    self.trainer.call_hook('on_validation_end', *args, **kwargs)
  File "/home/sandeep.nagar/anaconda3/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py", line 822, in call_hook
    trainer_hook(*args, **kwargs)
  File "/home/sandeep.nagar/anaconda3/lib/python3.8/site-packages/pytorch_lightning/trainer/callback_hook.py", line 177, in on_validation_end
    callback.on_validation_end(self, self.get_model())
  File "/home/sandeep.nagar/anaconda3/lib/python3.8/site-packages/pytorch_lightning/callbacks/model_checkpoint.py", line 167, in on_validation_end
    self.save_checkpoint(trainer, pl_module)
  File "/home/sandeep.nagar/anaconda3/lib/python3.8/site-packages/pytorch_lightning/callbacks/model_checkpoint.py", line 213, in save_checkpoint
    self._save_top_k_checkpoints(monitor_candidates, trainer, pl_module, epoch, filepath)
  File "/home/sandeep.nagar/anaconda3/lib/python3.8/site-packages/pytorch_lightning/callbacks/model_checkpoint.py", line 494, in _save_top_k_checkpoints
    self._update_best_and_save(filepath, current, epoch, trainer, pl_module)
  File "/home/sandeep.nagar/anaconda3/lib/python3.8/site-packages/pytorch_lightning/callbacks/model_checkpoint.py", line 543, in _update_best_and_save
    self._save_model(filepath, trainer, pl_module)
  File "/home/sandeep.nagar/anaconda3/lib/python3.8/site-packages/pytorch_lightning/callbacks/model_checkpoint.py", line 295, in _save_model
    self.save_function(filepath, self.save_weights_only)
  File "/home/sandeep.nagar/anaconda3/lib/python3.8/site-packages/pytorch_lightning/trainer/properties.py", line 191, in save_checkpoint
    self.checkpoint_connector.save_checkpoint(filepath, weights_only)
  File "/home/sandeep.nagar/anaconda3/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/checkpoint_connector.py", line 352, in save_checkpoint
    atomic_save(checkpoint, filepath)
  File "/home/sandeep.nagar/anaconda3/lib/python3.8/site-packages/pytorch_lightning/utilities/cloud_io.py", line 64, in atomic_save
    f.write(bytesbuffer.getvalue())
  File "/home/sandeep.nagar/anaconda3/lib/python3.8/site-packages/fsspec/core.py", line 121, in __exit__
    self.close()
  File "/home/sandeep.nagar/anaconda3/lib/python3.8/site-packages/fsspec/core.py", line 149, in close
    _close(self.fobjects, self.mode)
  File "/home/sandeep.nagar/anaconda3/lib/python3.8/site-packages/fsspec/core.py", line 209, in _close
    f.close()
OSError: [Errno 122] Disk quota exceeded
Exception ignored in: <function tqdm.__del__ at 0x151461d1c700>
Traceback (most recent call last):
  File "/home/sandeep.nagar/anaconda3/lib/python3.8/site-packages/tqdm/std.py", line 1086, in __del__
  File "/home/sandeep.nagar/anaconda3/lib/python3.8/site-packages/tqdm/std.py", line 1293, in close
  File "/home/sandeep.nagar/anaconda3/lib/python3.8/site-packages/tqdm/std.py", line 1471, in display
  File "/home/sandeep.nagar/anaconda3/lib/python3.8/site-packages/tqdm/std.py", line 1089, in __repr__
  File "/home/sandeep.nagar/anaconda3/lib/python3.8/site-packages/tqdm/std.py", line 1433, in format_dict
TypeError: cannot unpack non-iterable NoneType object

                                                           [A