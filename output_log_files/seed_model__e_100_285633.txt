==========================================
SLURM_JOB_ID = 285633
SLURM_NODELIST = gnode55
SLURM_JOB_GPUS = 3
==========================================
GPU available: True, used: True
TPU available: False, using: 0 TPU cores
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
Set SLURM handle signals.

  | Name    | Type   | Params
-----------------------------------
0 | alexnet | ResNet | 11 M  
Validation sanity check: 0it [00:00, ?it/s]Validation sanity check:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:02<00:02,  2.45s/it]                                                                      Training: 0it [00:00, ?it/s]Training:   0%|          | 0/70 [00:00<?, ?it/s]Epoch 0:   0%|          | 0/70 [00:00<?, ?it/s] /home/sandeep.nagar/anaconda3/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:45: UserWarning: The {log:dict keyword} was deprecated in 0.9.1 and will be removed in 1.0.0
Please use self.log(...) inside the lightningModule instead.

# log on a step or aggregate epoch metric to the logger and/or progress bar
# (inside LightningModule)
self.log('train_loss', loss, on_step=True, on_epoch=True, prog_bar=True)
  warnings.warn(*args, **kwargs)
Epoch 0:   1%|â–         | 1/70 [00:02<03:14,  2.82s/it]Epoch 0:   1%|â–         | 1/70 [00:02<03:14,  2.82s/it, loss=7.055, v_num=285633, train_acc=0]Epoch 0:   3%|â–Ž         | 2/70 [00:02<01:41,  1.50s/it, loss=7.055, v_num=285633, train_acc=0]Epoch 0:   3%|â–Ž         | 2/70 [00:02<01:41,  1.50s/it, loss=6.303, v_num=285633, train_acc=0.273]Epoch 0:   4%|â–         | 3/70 [00:03<01:10,  1.06s/it, loss=6.303, v_num=285633, train_acc=0.273]Epoch 0:   4%|â–         | 3/70 [00:03<01:10,  1.06s/it, loss=5.496, v_num=285633, train_acc=0.461]Epoch 0:   6%|â–Œ         | 4/70 [00:04<01:19,  1.20s/it, loss=5.496, v_num=285633, train_acc=0.461]Epoch 0:   6%|â–Œ         | 4/70 [00:04<01:19,  1.20s/it, loss=4.832, v_num=285633, train_acc=0.41] Epoch 0:   7%|â–‹         | 5/70 [00:05<01:05,  1.00s/it, loss=4.832, v_num=285633, train_acc=0.41]Epoch 0:   7%|â–‹         | 5/70 [00:05<01:05,  1.00s/it, loss=4.365, v_num=285633, train_acc=0.426]Epoch 0:   9%|â–Š         | 6/70 [00:05<00:55,  1.16it/s, loss=4.365, v_num=285633, train_acc=0.426]Epoch 0:   9%|â–Š         | 6/70 [00:05<00:55,  1.16it/s, loss=3.929, v_num=285633, train_acc=0.438]Epoch 0:  10%|â–ˆ         | 7/70 [00:05<00:48,  1.30it/s, loss=3.929, v_num=285633, train_acc=0.438]Epoch 0:  10%|â–ˆ         | 7/70 [00:05<00:48,  1.30it/s, loss=3.562, v_num=285633, train_acc=0.371]Epoch 0:  11%|â–ˆâ–        | 8/70 [00:07<00:54,  1.14it/s, loss=3.562, v_num=285633, train_acc=0.371]Epoch 0:  11%|â–ˆâ–        | 8/70 [00:07<00:54,  1.14it/s, loss=3.278, v_num=285633, train_acc=0.434]Epoch 0:  13%|â–ˆâ–Ž        | 9/70 [00:07<00:49,  1.24it/s, loss=3.278, v_num=285633, train_acc=0.434]Epoch 0:  13%|â–ˆâ–Ž        | 9/70 [00:07<00:49,  1.24it/s, loss=3.050, v_num=285633, train_acc=0.449]Epoch 0:  14%|â–ˆâ–        | 10/70 [00:07<00:44,  1.35it/s, loss=3.050, v_num=285633, train_acc=0.449]Epoch 0:  14%|â–ˆâ–        | 10/70 [00:07<00:44,  1.35it/s, loss=2.862, v_num=285633, train_acc=0.488]Epoch 0:  16%|â–ˆâ–Œ        | 11/70 [00:07<00:40,  1.45it/s, loss=2.862, v_num=285633, train_acc=0.488]Epoch 0:  16%|â–ˆâ–Œ        | 11/70 [00:07<00:40,  1.45it/s, loss=2.711, v_num=285633, train_acc=0.453]Epoch 0:  17%|â–ˆâ–‹        | 12/70 [00:09<00:45,  1.29it/s, loss=2.711, v_num=285633, train_acc=0.453]Epoch 0:  17%|â–ˆâ–‹        | 12/70 [00:09<00:45,  1.29it/s, loss=2.587, v_num=285633, train_acc=0.438]Epoch 0:  19%|â–ˆâ–Š        | 13/70 [00:09<00:41,  1.37it/s, loss=2.587, v_num=285633, train_acc=0.438]Epoch 0:  19%|â–ˆâ–Š        | 13/70 [00:09<00:41,  1.37it/s, loss=2.478, v_num=285633, train_acc=0.492]Epoch 0:  20%|â–ˆâ–ˆ        | 14/70 [00:09<00:38,  1.45it/s, loss=2.478, v_num=285633, train_acc=0.492]Epoch 0:  20%|â–ˆâ–ˆ        | 14/70 [00:09<00:38,  1.45it/s, loss=2.379, v_num=285633, train_acc=0.484]Epoch 0:  21%|â–ˆâ–ˆâ–       | 15/70 [00:09<00:36,  1.52it/s, loss=2.379, v_num=285633, train_acc=0.484]Epoch 0:  21%|â–ˆâ–ˆâ–       | 15/70 [00:09<00:36,  1.52it/s, loss=2.294, v_num=285633, train_acc=0.504]Epoch 0:  23%|â–ˆâ–ˆâ–Ž       | 16/70 [00:11<00:38,  1.39it/s, loss=2.294, v_num=285633, train_acc=0.504]Epoch 0:  23%|â–ˆâ–ˆâ–Ž       | 16/70 [00:11<00:38,  1.39it/s, loss=2.218, v_num=285633, train_acc=0.484]Epoch 0:  24%|â–ˆâ–ˆâ–       | 17/70 [00:11<00:36,  1.45it/s, loss=2.218, v_num=285633, train_acc=0.484]Epoch 0:  24%|â–ˆâ–ˆâ–       | 17/70 [00:11<00:36,  1.45it/s, loss=2.150, v_num=285633, train_acc=0.5]  Epoch 0:  26%|â–ˆâ–ˆâ–Œ       | 18/70 [00:11<00:34,  1.52it/s, loss=2.150, v_num=285633, train_acc=0.5]Epoch 0:  26%|â–ˆâ–ˆâ–Œ       | 18/70 [00:11<00:34,  1.52it/s, loss=2.090, v_num=285633, train_acc=0.527]Epoch 0:  27%|â–ˆâ–ˆâ–‹       | 19/70 [00:12<00:32,  1.58it/s, loss=2.090, v_num=285633, train_acc=0.527]Epoch 0:  27%|â–ˆâ–ˆâ–‹       | 19/70 [00:12<00:32,  1.58it/s, loss=2.034, v_num=285633, train_acc=0.578]Epoch 0:  29%|â–ˆâ–ˆâ–Š       | 20/70 [00:13<00:33,  1.50it/s, loss=2.034, v_num=285633, train_acc=0.578]Epoch 0:  29%|â–ˆâ–ˆâ–Š       | 20/70 [00:13<00:33,  1.50it/s, loss=1.993, v_num=285633, train_acc=0.484]Epoch 0:  30%|â–ˆâ–ˆâ–ˆ       | 21/70 [00:13<00:31,  1.55it/s, loss=1.993, v_num=285633, train_acc=0.484]Epoch 0:  30%|â–ˆâ–ˆâ–ˆ       | 21/70 [00:13<00:31,  1.55it/s, loss=1.692, v_num=285633, train_acc=0.512]Epoch 0:  31%|â–ˆâ–ˆâ–ˆâ–      | 22/70 [00:13<00:29,  1.61it/s, loss=1.692, v_num=285633, train_acc=0.512]Epoch 0:  31%|â–ˆâ–ˆâ–ˆâ–      | 22/70 [00:13<00:29,  1.61it/s, loss=1.467, v_num=285633, train_acc=0.555]Epoch 0:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 23/70 [00:13<00:28,  1.66it/s, loss=1.467, v_num=285633, train_acc=0.555]Epoch 0:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 23/70 [00:13<00:28,  1.66it/s, loss=1.327, v_num=285633, train_acc=0.539]Epoch 0:  34%|â–ˆâ–ˆâ–ˆâ–      | 24/70 [00:14<00:28,  1.63it/s, loss=1.327, v_num=285633, train_acc=0.539]Epoch 0:  34%|â–ˆâ–ˆâ–ˆâ–      | 24/70 [00:14<00:28,  1.63it/s, loss=1.243, v_num=285633, train_acc=0.496]Epoch 0:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 25/70 [00:14<00:26,  1.67it/s, loss=1.243, v_num=285633, train_acc=0.496]Epoch 0:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 25/70 [00:14<00:26,  1.67it/s, loss=1.173, v_num=285633, train_acc=0.527]Epoch 0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 26/70 [00:15<00:25,  1.72it/s, loss=1.173, v_num=285633, train_acc=0.527]Epoch 0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 26/70 [00:15<00:25,  1.72it/s, loss=1.139, v_num=285633, train_acc=0.527]Epoch 0:  39%|â–ˆâ–ˆâ–ˆâ–Š      | 27/70 [00:15<00:24,  1.76it/s, loss=1.139, v_num=285633, train_acc=0.527]Epoch 0:  39%|â–ˆâ–ˆâ–ˆâ–Š      | 27/70 [00:15<00:24,  1.76it/s, loss=1.124, v_num=285633, train_acc=0.488]Epoch 0:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 28/70 [00:16<00:24,  1.74it/s, loss=1.124, v_num=285633, train_acc=0.488]Epoch 0:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 28/70 [00:16<00:24,  1.74it/s, loss=1.111, v_num=285633, train_acc=0.562]Epoch 0:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 29/70 [00:16<00:23,  1.78it/s, loss=1.111, v_num=285633, train_acc=0.562]Epoch 0:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 29/70 [00:16<00:23,  1.78it/s, loss=1.097, v_num=285633, train_acc=0.566]Epoch 0:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 30/70 [00:16<00:21,  1.82it/s, loss=1.097, v_num=285633, train_acc=0.566]Epoch 0:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 30/70 [00:16<00:21,  1.82it/s, loss=1.094, v_num=285633, train_acc=0.496]Epoch 0:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 31/70 [00:16<00:20,  1.86it/s, loss=1.094, v_num=285633, train_acc=0.496]Epoch 0:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 31/70 [00:16<00:20,  1.86it/s, loss=1.087, v_num=285633, train_acc=0.523]Epoch 0:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 32/70 [00:17<00:20,  1.83it/s, loss=1.087, v_num=285633, train_acc=0.523]Epoch 0:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 32/70 [00:17<00:20,  1.83it/s, loss=1.076, v_num=285633, train_acc=0.555]Epoch 0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 33/70 [00:17<00:19,  1.87it/s, loss=1.076, v_num=285633, train_acc=0.555]Epoch 0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 33/70 [00:17<00:19,  1.87it/s, loss=1.069, v_num=285633, train_acc=0.543]Epoch 0:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 34/70 [00:17<00:19,  1.89it/s, loss=1.069, v_num=285633, train_acc=0.543]Epoch 0:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 34/70 [00:17<00:19,  1.89it/s, loss=1.064, v_num=285633, train_acc=0.543]Epoch 0:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 35/70 [00:18<00:18,  1.93it/s, loss=1.064, v_num=285633, train_acc=0.543]Epoch 0:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 35/70 [00:18<00:18,  1.93it/s, loss=1.063, v_num=285633, train_acc=0.52] Epoch 0:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 36/70 [00:18<00:17,  1.90it/s, loss=1.063, v_num=285633, train_acc=0.52]Epoch 0:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 36/70 [00:18<00:17,  1.90it/s, loss=1.057, v_num=285633, train_acc=0.578]Epoch 0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 37/70 [00:19<00:17,  1.94it/s, loss=1.057, v_num=285633, train_acc=0.578]Epoch 0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 37/70 [00:19<00:17,  1.94it/s, loss=1.057, v_num=285633, train_acc=0.516]Epoch 0:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 38/70 [00:19<00:16,  1.95it/s, loss=1.057, v_num=285633, train_acc=0.516]Epoch 0:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 38/70 [00:19<00:16,  1.95it/s, loss=1.054, v_num=285633, train_acc=0.551]Epoch 0:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 39/70 [00:19<00:15,  1.98it/s, loss=1.054, v_num=285633, train_acc=0.551]Epoch 0:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 39/70 [00:19<00:15,  1.98it/s, loss=1.057, v_num=285633, train_acc=0.52] Epoch 0:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 40/70 [00:20<00:15,  1.97it/s, loss=1.057, v_num=285633, train_acc=0.52]Epoch 0:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 40/70 [00:20<00:15,  1.97it/s, loss=1.050, v_num=285633, train_acc=0.535]Epoch 0:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 41/70 [00:20<00:14,  2.00it/s, loss=1.050, v_num=285633, train_acc=0.535]Epoch 0:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 41/70 [00:20<00:14,  2.00it/s, loss=1.052, v_num=285633, train_acc=0.512]Epoch 0:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 42/70 [00:20<00:13,  2.00it/s, loss=1.052, v_num=285633, train_acc=0.512]Epoch 0:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 42/70 [00:20<00:13,  2.00it/s, loss=1.053, v_num=285633, train_acc=0.547]Epoch 0:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 43/70 [00:21<00:13,  2.03it/s, loss=1.053, v_num=285633, train_acc=0.547]Epoch 0:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 43/70 [00:21<00:13,  2.03it/s, loss=1.051, v_num=285633, train_acc=0.516]Epoch 0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 44/70 [00:21<00:12,  2.02it/s, loss=1.051, v_num=285633, train_acc=0.516]Epoch 0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 44/70 [00:21<00:12,  2.02it/s, loss=1.044, v_num=285633, train_acc=0.527]Epoch 0:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 45/70 [00:21<00:12,  2.05it/s, loss=1.044, v_num=285633, train_acc=0.527]Epoch 0:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 45/70 [00:21<00:12,  2.05it/s, loss=1.041, v_num=285633, train_acc=0.555]Epoch 0:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 46/70 [00:22<00:11,  2.04it/s, loss=1.041, v_num=285633, train_acc=0.555]Epoch 0:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 46/70 [00:22<00:11,  2.04it/s, loss=1.037, v_num=285633, train_acc=0.547]Epoch 0:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 47/70 [00:22<00:11,  2.07it/s, loss=1.037, v_num=285633, train_acc=0.547]Epoch 0:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 47/70 [00:22<00:11,  2.07it/s, loss=1.035, v_num=285633, train_acc=0.543]Epoch 0:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 48/70 [00:23<00:10,  2.07it/s, loss=1.035, v_num=285633, train_acc=0.543]Epoch 0:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 48/70 [00:23<00:10,  2.07it/s, loss=1.031, v_num=285633, train_acc=0.605]Epoch 0:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 49/70 [00:23<00:10,  2.10it/s, loss=1.031, v_num=285633, train_acc=0.605]Epoch 0:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 49/70 [00:23<00:10,  2.10it/s, loss=1.030, v_num=285633, train_acc=0.594]Epoch 0:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 50/70 [00:24<00:09,  2.08it/s, loss=1.030, v_num=285633, train_acc=0.594]Epoch 0:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 50/70 [00:24<00:09,  2.08it/s, loss=1.027, v_num=285633, train_acc=0.531]Epoch 0:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 51/70 [00:24<00:09,  2.11it/s, loss=1.027, v_num=285633, train_acc=0.531]Epoch 0:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 51/70 [00:24<00:09,  2.11it/s, loss=1.021, v_num=285633, train_acc=0.586]Epoch 0:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 52/70 [00:24<00:08,  2.12it/s, loss=1.021, v_num=285633, train_acc=0.586]Epoch 0:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 52/70 [00:24<00:08,  2.12it/s, loss=1.022, v_num=285633, train_acc=0.535]Epoch 0:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 53/70 [00:24<00:07,  2.15it/s, loss=1.022, v_num=285633, train_acc=0.535]Epoch 0:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 53/70 [00:24<00:07,  2.15it/s, loss=1.022, v_num=285633, train_acc=0.57] Epoch 0:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 54/70 [00:25<00:07,  2.13it/s, loss=1.022, v_num=285633, train_acc=0.57]Epoch 0:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 54/70 [00:25<00:07,  2.13it/s, loss=1.022, v_num=285633, train_acc=0.59]Epoch 0:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 55/70 [00:25<00:06,  2.15it/s, loss=1.022, v_num=285633, train_acc=0.59]Epoch 0:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 55/70 [00:25<00:06,  2.15it/s, loss=1.017, v_num=285633, train_acc=0.574]Epoch 0:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 56/70 [00:25<00:06,  2.18it/s, loss=1.017, v_num=285633, train_acc=0.574]Epoch 0:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 56/70 [00:25<00:06,  2.18it/s, loss=1.017, v_num=285633, train_acc=0.597]
Validating: 0it [00:00, ?it/s][A/home/sandeep.nagar/anaconda3/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:45: UserWarning: The {progress_bar:dict keyword} was deprecated in 0.9.1 and will be removed in 1.0.0
Please use self.log(...) inside the lightningModule instead.

# log on a step or aggregate epoch metric to the logger and/or progress bar
# (inside LightningModule)
self.log('train_loss', loss, on_step=True, on_epoch=True, prog_bar=True)
  warnings.warn(*args, **kwargs)

Validating:   7%|â–‹         | 1/14 [00:01<00:15,  1.20s/it][AEpoch 0:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 57/70 [00:26<00:06,  2.12it/s, loss=1.017, v_num=285633, train_acc=0.597]
Validating:  14%|â–ˆâ–        | 2/14 [00:01<00:10,  1.12it/s][AEpoch 0:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 58/70 [00:27<00:05,  2.14it/s, loss=1.017, v_num=285633, train_acc=0.597]
Validating:  29%|â–ˆâ–ˆâ–Š       | 4/14 [00:01<00:06,  1.56it/s][AEpoch 0:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 60/70 [00:27<00:04,  2.20it/s, loss=1.017, v_num=285633, train_acc=0.597]
Validating:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 5/14 [00:02<00:06,  1.39it/s][A
Validating:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 6/14 [00:02<00:04,  1.72it/s][AEpoch 0:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 62/70 [00:28<00:03,  2.18it/s, loss=1.017, v_num=285633, train_acc=0.597]
Validating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 7/14 [00:02<00:03,  2.26it/s][AEpoch 0:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 64/70 [00:28<00:02,  2.24it/s, loss=1.017, v_num=285633, train_acc=0.597]
Validating:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 9/14 [00:03<00:02,  2.05it/s][A
Validating:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 10/14 [00:04<00:01,  2.43it/s][AEpoch 0:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 66/70 [00:29<00:01,  2.21it/s, loss=1.017, v_num=285633, train_acc=0.597]
Validating:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 11/14 [00:04<00:01,  2.70it/s][AEpoch 0:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 68/70 [00:30<00:00,  2.25it/s, loss=1.017, v_num=285633, train_acc=0.597]
Validating:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 13/14 [00:05<00:00,  2.41it/s][AEpoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 70/70 [00:31<00:00,  2.24it/s, loss=1.017, v_num=285633, train_acc=0.597]Traceback (most recent call last):
  File "main.py", line 148, in <module>
    trainer.fit(model)
  File "/home/sandeep.nagar/anaconda3/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py", line 439, in fit
    results = self.accelerator_backend.train()
  File "/home/sandeep.nagar/anaconda3/lib/python3.8/site-packages/pytorch_lightning/accelerators/gpu_accelerator.py", line 54, in train
    results = self.train_or_test()
  File "/home/sandeep.nagar/anaconda3/lib/python3.8/site-packages/pytorch_lightning/accelerators/accelerator.py", line 66, in train_or_test
    results = self.trainer.train()
  File "/home/sandeep.nagar/anaconda3/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py", line 482, in train
    self.train_loop.run_training_epoch()
  File "/home/sandeep.nagar/anaconda3/lib/python3.8/site-packages/pytorch_lightning/trainer/training_loop.py", line 569, in run_training_epoch
    self.trainer.run_evaluation(test_mode=False)
  File "/home/sandeep.nagar/anaconda3/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py", line 609, in run_evaluation
    self.evaluation_loop.on_evaluation_end()
  File "/home/sandeep.nagar/anaconda3/lib/python3.8/site-packages/pytorch_lightning/trainer/evaluation_loop.py", line 109, in on_evaluation_end
    self.trainer.call_hook('on_validation_end', *args, **kwargs)
  File "/home/sandeep.nagar/anaconda3/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py", line 822, in call_hook
    trainer_hook(*args, **kwargs)
  File "/home/sandeep.nagar/anaconda3/lib/python3.8/site-packages/pytorch_lightning/trainer/callback_hook.py", line 177, in on_validation_end
    callback.on_validation_end(self, self.get_model())
  File "/home/sandeep.nagar/anaconda3/lib/python3.8/site-packages/pytorch_lightning/callbacks/model_checkpoint.py", line 167, in on_validation_end
    self.save_checkpoint(trainer, pl_module)
  File "/home/sandeep.nagar/anaconda3/lib/python3.8/site-packages/pytorch_lightning/callbacks/model_checkpoint.py", line 213, in save_checkpoint
    self._save_top_k_checkpoints(monitor_candidates, trainer, pl_module, epoch, filepath)
  File "/home/sandeep.nagar/anaconda3/lib/python3.8/site-packages/pytorch_lightning/callbacks/model_checkpoint.py", line 494, in _save_top_k_checkpoints
    self._update_best_and_save(filepath, current, epoch, trainer, pl_module)
  File "/home/sandeep.nagar/anaconda3/lib/python3.8/site-packages/pytorch_lightning/callbacks/model_checkpoint.py", line 543, in _update_best_and_save
    self._save_model(filepath, trainer, pl_module)
  File "/home/sandeep.nagar/anaconda3/lib/python3.8/site-packages/pytorch_lightning/callbacks/model_checkpoint.py", line 295, in _save_model
    self.save_function(filepath, self.save_weights_only)
  File "/home/sandeep.nagar/anaconda3/lib/python3.8/site-packages/pytorch_lightning/trainer/properties.py", line 191, in save_checkpoint
    self.checkpoint_connector.save_checkpoint(filepath, weights_only)
  File "/home/sandeep.nagar/anaconda3/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/checkpoint_connector.py", line 352, in save_checkpoint
    atomic_save(checkpoint, filepath)
  File "/home/sandeep.nagar/anaconda3/lib/python3.8/site-packages/pytorch_lightning/utilities/cloud_io.py", line 64, in atomic_save
    f.write(bytesbuffer.getvalue())
  File "/home/sandeep.nagar/anaconda3/lib/python3.8/site-packages/fsspec/core.py", line 121, in __exit__
    self.close()
  File "/home/sandeep.nagar/anaconda3/lib/python3.8/site-packages/fsspec/core.py", line 149, in close
    _close(self.fobjects, self.mode)
  File "/home/sandeep.nagar/anaconda3/lib/python3.8/site-packages/fsspec/core.py", line 209, in _close
    f.close()
OSError: [Errno 122] Disk quota exceeded
Exception ignored in: <function tqdm.__del__ at 0x151461d1c700>
Traceback (most recent call last):
  File "/home/sandeep.nagar/anaconda3/lib/python3.8/site-packages/tqdm/std.py", line 1086, in __del__
  File "/home/sandeep.nagar/anaconda3/lib/python3.8/site-packages/tqdm/std.py", line 1293, in close
  File "/home/sandeep.nagar/anaconda3/lib/python3.8/site-packages/tqdm/std.py", line 1471, in display
  File "/home/sandeep.nagar/anaconda3/lib/python3.8/site-packages/tqdm/std.py", line 1089, in __repr__
  File "/home/sandeep.nagar/anaconda3/lib/python3.8/site-packages/tqdm/std.py", line 1433, in format_dict
TypeError: cannot unpack non-iterable NoneType object

                                                           [A