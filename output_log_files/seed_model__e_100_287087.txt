==========================================
SLURM_JOB_ID = 287087
SLURM_NODELIST = gnode59
SLURM_JOB_GPUS = 2
==========================================
GPU available: True, used: True
TPU available: False, using: 0 TPU cores
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
Set SLURM handle signals.

  | Name    | Type   | Params
-----------------------------------
0 | alexnet | ResNet | 11 M  
Validation sanity check: 0it [00:00, ?it/s]Traceback (most recent call last):
  File "main.py", line 148, in <module>
    trainer.fit(model)
  File "/home/sandeep.nagar/anaconda3/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py", line 439, in fit
    results = self.accelerator_backend.train()
  File "/home/sandeep.nagar/anaconda3/lib/python3.8/site-packages/pytorch_lightning/accelerators/gpu_accelerator.py", line 54, in train
    results = self.train_or_test()
  File "/home/sandeep.nagar/anaconda3/lib/python3.8/site-packages/pytorch_lightning/accelerators/accelerator.py", line 66, in train_or_test
    results = self.trainer.train()
  File "/home/sandeep.nagar/anaconda3/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py", line 461, in train
    self.run_sanity_check(self.get_model())
  File "/home/sandeep.nagar/anaconda3/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py", line 647, in run_sanity_check
    _, eval_results = self.run_evaluation(test_mode=False, max_batches=self.num_sanity_val_batches)
  File "/home/sandeep.nagar/anaconda3/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py", line 555, in run_evaluation
    for batch_idx, batch in enumerate(dataloader):
  File "/home/sandeep.nagar/anaconda3/lib/python3.8/site-packages/torch/utils/data/dataloader.py", line 363, in __next__
    data = self._next_data()
  File "/home/sandeep.nagar/anaconda3/lib/python3.8/site-packages/torch/utils/data/dataloader.py", line 989, in _next_data
    return self._process_data(data)
  File "/home/sandeep.nagar/anaconda3/lib/python3.8/site-packages/torch/utils/data/dataloader.py", line 1014, in _process_data
    data.reraise()
  File "/home/sandeep.nagar/anaconda3/lib/python3.8/site-packages/torch/_utils.py", line 395, in reraise
    raise self.exc_type(msg)
RuntimeError: Caught RuntimeError in DataLoader worker process 0.
Original Traceback (most recent call last):
  File "/home/sandeep.nagar/anaconda3/lib/python3.8/site-packages/torch/utils/data/_utils/worker.py", line 185, in _worker_loop
    data = fetcher.fetch(index)
  File "/home/sandeep.nagar/anaconda3/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py", line 44, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/sandeep.nagar/anaconda3/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py", line 44, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/sandeep.nagar/lit_pytorch_seeds/load_data.py", line 103, in __getitem__
    X = self.transform(X)   ##   H x W x C to    C x H x W and some other transformations
  File "/home/sandeep.nagar/anaconda3/lib/python3.8/site-packages/torchvision/transforms/transforms.py", line 61, in __call__
    img = t(img)
  File "/home/sandeep.nagar/anaconda3/lib/python3.8/site-packages/torchvision/transforms/transforms.py", line 212, in __call__
    return F.normalize(tensor, self.mean, self.std, self.inplace)
  File "/home/sandeep.nagar/anaconda3/lib/python3.8/site-packages/torchvision/transforms/functional.py", line 298, in normalize
    tensor.sub_(mean).div_(std)
RuntimeError: The size of tensor a (4) must match the size of tensor b (3) at non-singleton dimension 0

                                           